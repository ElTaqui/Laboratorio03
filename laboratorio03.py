# -*- coding: utf-8 -*-
"""Laboratorio03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1geFEP66gNViMpOI4fkxshx_TaeCNZRLP

# Ya revisado en clases

Taquichiri Huarita Luis Alexander

Subir librerías
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
from matplotlib import pyplot
from scipy import optimize
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# %matplotlib inline

"""Cargar y revisar el data set"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
data = pd.read_csv('/content/creditcard.csv', delimiter=',', decimal='.')
data = data.dropna()
data.info()

"""Establecer las varibles desde el dataset"""

X, y = data.iloc[:10000, :30].values, data.iloc[:10000, 30].values
X_predic, y_predic = data.iloc[10000:12500, :30].values, data.iloc[10000:12500, 30].values
print(X)
print(y)

"""Funcion normalización"""

def  featureNormalize(X):
    X_norm = X.copy()
    mu = np.zeros(X.shape[1])
    sigma = np.zeros(X.shape[1])
    mu = np.mean(X, axis = 0)
    sigma = np.std(X, axis = 0)
    X_norm = (X - mu) / sigma

    return X_norm, mu, sigma

"""Normalización"""

X_norm, mu, sigma = featureNormalize(X)
X_predic, mu_predic, sigma_predic = featureNormalize(X_predic)

print('Media calculada:\n', mu)
print('Desviación estandar calculada:\n', sigma)
print(X_norm)

"""Funcion zigmoidea"""

def sigmoid(z):
    z = np.array(z)
    g = np.zeros(z.shape)
    g = 1 / (1 + np.exp(-z))

    return g

"""Concatenamos el x0 para los datos de entrenamiento y los datos de prueba"""

m= X.shape[0]
m_predic= X_predic.shape[0]
X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)
X_predic = np.concatenate([np.ones((m_predic, 1)), X_predic], axis=1)

"""Funcion para calcular el costo"""

def calcularCosto(theta, X, y):
    J = 0
    h = sigmoid(X.dot(theta.T))
    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))

    return J

"""Funcion que calcula theta mediante el descenso por el gradiente"""

def descensoGradiente(theta, X, y, alpha, num_iters):
    theta = theta.copy()
    J_history = []
    for i in range(num_iters):
        h = sigmoid(X.dot(theta.T))
        theta = theta - (alpha / m) * (h - y).dot(X)

        J_history.append(calcularCosto(theta, X, y))

    return theta, J_history

"""Ejecución de las funciones para entrenar al modelo"""

alpha = 0.003
num_iters = 16000

theta = np.zeros(X.shape[1])
theta, J_history = descensoGradiente(theta, X, y, alpha, num_iters)

# Grafica la convergencia del costo
pyplot.plot(np.arange(len(J_history)), J_history, lw=2)
pyplot.xlabel('Numero de iteraciones')
pyplot.ylabel('Costo J')

print('J: ',J_history[-1])
print('--------------------------------------------------------------------------')
# Muestra los resultados del descenso por el gradiente
print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))
print('--------------------------------------------------------------------------')

"""Funcion saca todos los datos predichos con los thetas calculados"""

def predictEntre(theta, X):
    p = np.zeros(m)
    p = np.round(sigmoid(X.dot(theta.T)))
    return p

"""Prueba de eficacia en porcentaje con los datos de entrenamiento"""

p = predictEntre(theta, X)
print('Precisión de entrenamiento: {:.2f} %'.format(np.mean(p == y) * 100))

"""Medicion de eficacia con Datos de prueba"""

def predictPrue(theta, X):
    p = np.zeros(m_predic)
    p = np.round(sigmoid(X.dot(theta.T)))
    return p

p_predic = predictPrue(theta, X_predic)
print('Precisión de entrenamiento: {:.2f} %'.format(np.mean(p_predic == y_predic) * 100))

for i in range(m_predic):
  X_array = np.array(X_predic[i])
  Prediccion = np.round(sigmoid(np.dot(X_array, theta)))
  print('La predicción es: ',Prediccion,'El valor original es de: ', y_predic[i])

"""Prueba de Regresión, Predicción y La Medida de Precisción de ests con Sklearn:"""

X_new = X_predic
y_new = y_predic

model = LogisticRegression()
model.fit(X, y)

y_pred_new = model.predict(X_new)

# Calcula las métricas de evaluación en porcentajes
accuracy_new = accuracy_score(y_new, y_pred_new) * 100
precision_new = precision_score(y_new, y_pred_new) * 100
recall_new = recall_score(y_new, y_pred_new) * 100
f1_new = f1_score(y_new, y_pred_new) * 100

if len(set(y_new)) > 1:
    roc_auc_new = roc_auc_score(y_new, y_pred_new) * 100
else:
    roc_auc_new = "No es posible calcular el ROC-AUC con una sola clase."

cm_new = confusion_matrix(y_new, y_pred_new)

# Imprime los resultados en porcentajes
print(f"Exactitud (Accuracy) con nuevos datos: {accuracy_new:.2f}%")
print(f"Precisión (Precision) con nuevos datos: {precision_new:.2f}%")
print(f"Recall con nuevos datos: {recall_new:.2f}%")
print(f"F1-Score con nuevos datos: {f1_new:.2f}%")
print(f"ROC-AUC con nuevos datos: {roc_auc_new}")
print(f"Matriz de Confusión con nuevos datos:\n{cm_new}")